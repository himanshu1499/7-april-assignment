{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930ec82-fca9-4554-beb9-fdef8cdbcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b99aa-77e6-4495-bb12-a2523ca6a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial functions and kernel functions are both types of mathematical functions that can be used in machine learning algorithms, particularly in support vector machines (SVMs) and kernel-based methods.\n",
    "\n",
    "Polynomial functions are a type of function that can be used to transform the input features of a dataset into a higher-dimensional space. \n",
    "This can be useful for creating decision boundaries that are not linear, as the polynomial features can help capture nonlinear relationships between the input features and the target variable. \n",
    "\n",
    "Kernel functions, on the other hand, are used to measure the similarity between pairs of data points.\n",
    "Kernel functions operate on the original feature space, but can also be used to implicitly transform the data into a higher-dimensional feature space.\n",
    "This can be useful for capturing complex relationships between the input features and the target variable without explicitly computing the high-dimensional feature space.\n",
    "\n",
    "Some types of kernel functions, such as the polynomial kernel, are based on polynomial functions and can be used to implicitly transform the input features into a higher-dimensional space. \n",
    "In this way, kernel functions and polynomial functions are related in that they both involve transforming data into a higher-dimensional space, but kernel functions do so implicitly and are often more computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6976710-4974-4cd8-83b8-ba765e942657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cfdf619-3195-4d50-ac5e-f444527fed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate some random data to work with\n",
    "X, y = make_classification(n_samples=2000, n_features=10, n_informative=5, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the SVM classifier with a polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3, gamma='scale', C=1.0)\n",
    "\n",
    "# Train the SVM classifier on the training data\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Test the SVM classifier on the testing data and evaluate its performance\n",
    "score = svm_poly.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbf277-00af-4d84-a59f-f8bde938435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1720066-2029-4f74-a49b-7610c60cb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Support Vector Regression (SVR), the epsilon parameter controls the width of the epsilon-insensitive zone around the regression line.\n",
    "An epsilon value of 0 indicates that there is no margin and any data point that falls on or outside the regression line will be considered an error. \n",
    "As the value of epsilon increases, the margin around the regression line also increases, allowing more data points to be within the margin and considered correctly predicted.\n",
    "\n",
    "When the value of epsilon is increased, the number of support vectors generally increases. \n",
    "This is because more data points are now considered within the margin, which requires more support vectors to define the regression line.\n",
    "the exact relationship between epsilon and the number of support vectors depends on the specific dataset and the other hyperparameters of the SVR algorithm. \n",
    "In some cases, increasing epsilon may even decrease the number of support vectors if the new margin includes a large number of correctly predicted data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43aa8f-e148-4bab-9de0-9339ad4582bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e127e7-beaf-4ee1-bfec-63554ab2657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "The performance of Support Vector Regression (SVR) is highly dependent on the choice of kernel function, C parameter, epsilon parameter, and gamma parameter. Here is how each parameter works and how changing its value can affect the performance of SVR:\n",
    "\n",
    "1. Kernel Function: The kernel function maps the original data to a higher-dimensional feature space where the problem becomes more easily separable. The choice of kernel function can have a significant impact on the performance of SVR. Popular kernel functions include linear, polynomial, and radial basis function (RBF). Linear kernel is suitable for linearly separable datasets while polynomial kernel and RBF kernel are used for non-linearly separable datasets.\n",
    "\n",
    "2. C Parameter: The C parameter controls the trade-off between achieving a low training error and a low testing error by controlling the degree of misclassification that is tolerated in the training data. A low value of C creates a wider margin around the decision boundary, allowing more misclassifications in the training data but resulting in a simpler and more generalized model. Conversely, a high value of C creates a narrower margin and tolerates fewer misclassifications in the training data, resulting in a more complex model that may overfit the training data. Therefore, the choice of C parameter is a balance between underfitting and overfitting.\n",
    "\n",
    "3. Epsilon Parameter: The epsilon parameter controls the width of the epsilon-insensitive zone around the regression line in SVR. The epsilon-insensitive zone allows some errors in the prediction, as long as they are within the zone. A larger value of epsilon creates a wider zone, allowing more errors in the prediction but resulting in a simpler and more generalized model. Conversely, a smaller value of epsilon creates a narrower zone, allowing fewer errors in the prediction, resulting in a more complex model that may overfit the training data.\n",
    "\n",
    "4. Gamma Parameter: The gamma parameter is specific to the RBF kernel function and controls the smoothness of the decision boundary. A low value of gamma creates a smoother decision boundary, resulting in a more generalized model. Conversely, a high value of gamma creates a more complex decision boundary that may overfit the training data. Therefore, the choice of gamma parameter is a balance between underfitting and overfitting.\n",
    "\n",
    "Here are some examples of when you might want to increase or decrease each parameter:\n",
    "\n",
    "1. Kernel Function: If the dataset is linearly separable, a linear kernel should be used. For non-linearly separable datasets, a polynomial or RBF kernel can be used depending on the complexity of the dataset.\n",
    "\n",
    "2. C Parameter: If the model is underfitting, the value of C should be decreased to create a wider margin and allow more misclassifications in the training data. If the model is overfitting, the value of C should be increased to create a narrower margin and tolerate fewer misclassifications in the training data.\n",
    "\n",
    "3. Epsilon Parameter: If the model is underfitting, the value of epsilon should be decreased to create a narrower epsilon-insensitive zone and tolerate fewer errors in the prediction. If the model is overfitting, the value of epsilon should be increased to create a wider epsilon-insensitive zone and allow more errors in the prediction.\n",
    "\n",
    "4. Gamma Parameter: If the model is underfitting, the value of gamma should be decreased to create a smoother decision boundary. If the model is overfitting, the value of gamma should be increased to create a more complex decision boundary that better fits the training data. However, too high gamma can lead to overfitting, so the choice of gamma should be carefully balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4e9491-9cfb-481f-baa3-c71d26950b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947dfd29-e050-49b0-9195-608dccfddf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9733333333333334\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END ....C=0.1, degree=2, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, degree=2, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, degree=2, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, degree=2, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, degree=2, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, degree=2, kernel=poly;, score=0.467 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, degree=2, kernel=poly;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, degree=2, kernel=poly;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, degree=2, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, degree=2, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, degree=2, kernel=rbf;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, degree=2, kernel=rbf;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, degree=2, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, degree=3, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, degree=3, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, degree=3, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, degree=3, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, degree=3, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, degree=3, kernel=poly;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, degree=3, kernel=poly;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, degree=3, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, degree=3, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, degree=3, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, degree=3, kernel=rbf;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, degree=3, kernel=rbf;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, degree=3, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, degree=4, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, degree=4, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, degree=4, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, degree=4, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, degree=4, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, degree=4, kernel=poly;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, degree=4, kernel=poly;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, degree=4, kernel=poly;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, degree=4, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, degree=4, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, degree=4, kernel=rbf;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, degree=4, kernel=rbf;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, degree=4, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, degree=2, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, degree=2, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, degree=2, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, degree=2, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, degree=2, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, degree=2, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, degree=2, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, degree=2, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, degree=2, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, degree=2, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, degree=2, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, degree=3, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, degree=3, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, degree=3, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, degree=3, kernel=poly;, score=0.733 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, degree=3, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, degree=3, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, degree=3, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, degree=3, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, degree=3, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, degree=3, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, degree=3, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, degree=4, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, degree=4, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, degree=4, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, degree=4, kernel=poly;, score=0.733 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, degree=4, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, degree=4, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, degree=4, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, degree=4, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, degree=4, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, degree=4, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, degree=4, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, degree=2, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, degree=2, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, degree=2, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, degree=2, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, degree=2, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, degree=2, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, degree=2, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, degree=2, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, degree=2, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, degree=2, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, degree=2, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, degree=2, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, degree=3, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, degree=3, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, degree=3, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, degree=3, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, degree=3, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, degree=3, kernel=poly;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, degree=3, kernel=poly;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, degree=3, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, degree=3, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, degree=3, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, degree=3, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, degree=3, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, degree=4, kernel=linear;, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, degree=4, kernel=linear;, score=0.933 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, degree=4, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, degree=4, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, degree=4, kernel=poly;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, degree=4, kernel=poly;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, degree=4, kernel=poly;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, degree=4, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, degree=4, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, degree=4, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, degree=4, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, degree=4, kernel=rbf;, score=0.933 total time=   0.0s\n",
      "Best Parameters: {'C': 0.1, 'degree': 2, 'kernel': 'linear'}\n",
      "Best Score: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "# Load the dataset\n",
    "df = sns.load_dataset('iris')\n",
    "\n",
    "# Split dataset into features and labels\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=45)\n",
    "\n",
    "# Preprocess the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score:\", acc_score)\n",
    "\n",
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf'], 'degree': [2, 3, 4]}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Score:\", grid.best_score_)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "clf_tuned = grid.best_estimator_\n",
    "clf_tuned.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "filename = 'svm_classifier.pkl'\n",
    "pickle.dump(clf_tuned, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1a97d-6cbd-4856-a123-0da5f41745fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
